# Desafio â€“ Agentes Conversacionais

Este projeto implementa um sistema **multiagente** para anÃ¡lise de avaliaÃ§Ãµes de restaurantes, conforme desafio tÃ©cnico proposto.  
O objetivo Ã© processar avaliaÃ§Ãµes textuais, extrair escores e calcular automaticamente uma pontuaÃ§Ã£o final para cada restaurante.

---

## âš™ï¸ Tecnologias Utilizadas

- **Python 3.11+**
- **autogen** (coordenaÃ§Ã£o dos agentes LLM)
- **regex/json** para parsing e validaÃ§Ã£o
- **logging** para rastreabilidade
- **python-dotenv** para carregar variÃ¡veis do `.env`

---

## ğŸ”‘ ConfiguraÃ§Ã£o do `.env`

Crie um arquivo chamado `.env` na raiz do projeto e adicione sua chave da LLM:

```env
OPENAI_API_KEY="sua_chave_aqui"
```
O projeto jÃ¡ carrega automaticamente o `.env` no `main.py`.

---

## ğŸš€ ExecuÃ§Ã£o

### 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/agentes-conversacionais.git
cd agentes-conversacionais
```

### 2. Criar ambiente virtual
```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

### 3. Instalar dependÃªncias
```bash
pip install -r requirements.txt
```

### 4. Configurar `.env`
Crie o arquivo `.env` e adicione sua chave conforme explicado acima.

### 5. Rodar o sistema
Exemplo de execuÃ§Ã£o com consulta:
```bash
python main.py "Qual Ã© a avaliaÃ§Ã£o mÃ©dia do Bob's?"
```

SaÃ­da esperada:
```
A avaliaÃ§Ã£o mÃ©dia do Bob's Ã© 3.79
```

---

## ğŸ§ª Testes

O arquivo `teste.py` contÃ©m testes automatizados fornecidos pelo desafio.  
Execute com:
```bash
python teste.py
```

SaÃ­da esperada:
```
Teste 1 Passou. Esperado: 3.79 ...
Teste 2 Passou. Esperado: 6.19 ...
Teste 3 Passou. Esperado: 4.64 ...
Teste 4 Passou. Esperado: 4.64 ...
4/4 Testes Passaram
```

---

## ğŸ”’ Tratamento de ExceÃ§Ãµes

O sistema **nÃ£o possui fallback** caso a LLM esteja indisponÃ­vel.  
Foram implementados tratamentos bÃ¡sicos para:
- Erros de leitura do dataset (`restaurantes.txt`).
- Resposta invÃ¡lida da LLM (ex.: nÃ£o-JSON ou fora da escala 1â€“5).
- Scores inconsistentes.

---

## ğŸ“‚ Fluxo de Funcionamento

```mermaid
flowchart LR
    User[UsuÃ¡rio] --> Orchestrator
    Orchestrator --> Fetch[data_fetch_agent]
    Fetch --> Reviews[Restaurantes.txt]
    Fetch --> Analysis[review_analysis_agent]
    Analysis --> Score[score_agent]
    Score --> Orchestrator
    Orchestrator --> User
```

---

## ğŸ“Œ Exemplo de Perguntas

- `Qual Ã© a avaliaÃ§Ã£o mÃ©dia do Paris 6?`
- `QuÃ£o bom Ã© o restaurante KFC?`
- `Qual Ã© a avaliaÃ§Ã£o mÃ©dia do China in Box?`
